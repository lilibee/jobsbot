{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Job Posting Data from Indeed \n",
    "Source:\n",
    "https://towardsdatascience.com/scraping-job-posting-data-from-indeed-using-selenium-and-beautifulsoup-dfc86230baac\n",
    "\n",
    "strategy:\n",
    "\n",
    "* Get the job posting links filtered for correct title in order to save scraping time for not relevant jobs\n",
    "* Click each link and parse text from the job posting page \n",
    "* get rid of duplicates \n",
    "* Store the parsed text data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get all the job posting links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all import statements\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# to write from list to csv file\n",
    "import csv\n",
    "import string    # need string to clean title\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " \"\"\"\n",
    "    Given the url of a page, this function returns the soup object.\n",
    "    \n",
    "    Parameters:\n",
    "        url: the link to get soup object for\n",
    "    \n",
    "    Returns:\n",
    "        soup: soup object\n",
    "    \"\"\"\n",
    "\n",
    "def get_soup(url):\n",
    "    driver = webdriver.Chrome(\"C:/Users/lili/Documents/icode/scraping/chromedriver\")\n",
    "    driver.get(url)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    driver.close()\n",
    "    return soup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \"\"\"\n",
    "    Grab all non-sponsored job posting links from a Indeed search result page using the given soup object\n",
    "    filter for postings with no keywords in title\n",
    "    \n",
    "    Parameters:\n",
    "        soup: the soup object corresponding to a search result page\n",
    "                e.g. https://ca.indeed.com/jobs?q=data+scientist&l=Toronto&start=20\n",
    "        key_words: the specific job title we are filtering for \n",
    "                    e.g. \"data\" and \"analyst\"\n",
    "        base_url: enalbes us to search in different indeed domains il.indeed vs. ca.indeed for example\n",
    "    \n",
    "    Returns:\n",
    "        urls: a python list of job posting urls\n",
    "    \n",
    "    \"\"\"\n",
    "def grab_job_links(soup, key_words, base_url):\n",
    "    urls = []\n",
    "    for link in soup.find_all('h2', {'class': 'jobtitle'}):\n",
    "        partial_url = link.a.get('href')\n",
    "        t = link.a.get('title').lower()\n",
    "        t = t.split()\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        t_stripped = [w.translate(table) for w in t]\n",
    "        print(t)\n",
    "        if (key_words[0] in t_stripped ) and (key_words[1] in t_stripped ):\n",
    "            print(\"yessss\")\n",
    "            url = base_url + partial_url\n",
    "            urls.append(url)\n",
    "        else:\n",
    "            continue\n",
    "    return urls\n",
    "\n",
    "# to improve the filtering works only for two words titles like data + analyst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " \"\"\"\n",
    "    Grab number of result pages, from a Indeed search result page using the given soup object\n",
    "    \n",
    "    Parameters:\n",
    "        soup: the soup object corresponding to a search result page\n",
    "                e.g. https://ca.indeed.com/jobs?q=data+scientist&l=Toronto&start=20\n",
    "    \n",
    "    Returns:\n",
    "        num_pages: integer number of result pages\n",
    "    \n",
    "    \"\"\"\n",
    "def grab_num_pages(soup):\n",
    "    page_in_search = soup.find(name='div', attrs={'id':\"searchCount\"}).get_text()\n",
    "    p = re.compile('(\\d+,*\\d*)')\n",
    "    num_pages = p.findall(page_in_search)\n",
    "    \n",
    "    # have to deal with comma delimited numbers which can't be turned into integer unless the comma is deleted\n",
    "    \n",
    "    num_pages = int(num_pages[1].replace(',',''))\n",
    "    return num_pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Get all the job posting URLs resulted from a specific search.\n",
    "    \n",
    "    Parameters:\n",
    "        query: job title to query\n",
    "        num_pages: number of pages needed\n",
    "        location: city to search in\n",
    "    \n",
    "    Returns:\n",
    "        urls: a list of job posting URL's (when num_pages valid)\n",
    "        max_pages: maximum number of pages allowed ((when num_pages invalid))\n",
    "    \"\"\"\n",
    "\n",
    "def get_urls(base_url1, query, location):\n",
    "    # We always need the first page\n",
    "    base_url = 'https://{}.com/jobs?q={}&l={}'.format(base_url1, query, location)\n",
    "    soup = get_soup(base_url)\n",
    "    urls = grab_job_links(soup, (query.split('+')), 'indeed')\n",
    "    num_listings = grab_num_pages(soup)\n",
    "    print(\"num_listings\",num_listings)\n",
    "    num_pages_calc = int(num_listings/10)\n",
    "    print(\"num_pages_calc\",num_pages_calc)\n",
    "     \n",
    "\n",
    "    # starting page 2\n",
    "    for i in range(2, num_pages_calc+1):\n",
    "            num = (i-1) * 10\n",
    "            base_url = 'https://{}.com/jobs?q={}&l={}&start={}'.format(base_url1, query, location, num)\n",
    "            try:\n",
    "                soup = get_soup(base_url)\n",
    "                # We always combine the results back to the list\n",
    "                urls += grab_job_links(soup, (query.split('+')),'indeed')\n",
    "            except:\n",
    "                continue\n",
    "    return urls\n",
    "                \n",
    "\n",
    "    \n",
    "# finished stage 1 we have urls a list  with job posting links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['junior', 'data', 'scientist']\n",
      "yessss\n",
      "['statistical', 'research', 'and', 'data', 'science', 'intern']\n",
      "['data', 'scientist,', 'sales', 'analytics']\n",
      "yessss\n",
      "['research', 'analyst,', 'people', 'analytics']\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist', '-', 'trello', '(remote)']\n",
      "yessss\n",
      "['junior', 'data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist', '–', 'personalization']\n",
      "yessss\n",
      "['data', 'scientist', 'i']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "num_listings 2980\n",
      "num_pages_calc 298\n",
      "['data', 'scientist,', 'analytics,', 'university', 'grad']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist', '–', 'content', 'marketing', 'acquisition']\n",
      "yessss\n",
      "['data', 'analyst', '-', 'user', 'research']\n",
      "['statistical', 'research', 'and', 'data', 'science', 'intern']\n",
      "['senior', 'data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist', 'summer', 'intern']\n",
      "yessss\n",
      "['data', 'scientist', '-', 'machine', 'learning']\n",
      "yessss\n",
      "['associate', 'data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist', 'intern']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['customer', 'experience', 'analyst', '(data', 'scientist)']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['senior', 'data', 'scientist']\n",
      "yessss\n",
      "['analyst,', 'data', 'and', 'analysis']\n",
      "['junior', 'data', 'scientist']\n",
      "yessss\n",
      "['analytics', 'consultant']\n",
      "['data', '&', 'analysis', 'coordinator']\n",
      "['sr', 'analyst,', 'data', '&', 'analysis']\n",
      "['data', 'scientist', 'i']\n",
      "yessss\n",
      "['research', 'analyst,', 'performance', 'management', 'design']\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['custom', 'insights,', 'research', 'analyst']\n",
      "['data', 'engineer']\n",
      "['data', 'scientist', '|', 'uber', 'for', 'business', '(nyc)']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['intern,', 'data', 'science']\n",
      "['custom', 'insights,', 'research', 'analyst']\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['data', 'analyst/modeler']\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['analyst,', 'data', '&', 'analysis']\n",
      "['customer', 'experience', 'analyst', '(data', 'scientist)']\n",
      "yessss\n",
      "['alphastudio', 'data', 'science', 'intern']\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['sr.', 'data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['analyst,', 'data', 'and', 'analysis']\n",
      "['intern,', 'data', 'science', '-', 'part-time']\n",
      "['decision', 'sciences', 'fall', '2019', 'data', 'science', 'practica', '–', 'new', 'york,', 'ny']\n",
      "['senior', 'data', 'scientist', 'intern']\n",
      "yessss\n",
      "['data', 'scientist', 'i']\n",
      "yessss\n",
      "['ecommerce', 'data', 'reporting', 'analyst']\n",
      "['data', 'scientist,', 'redtech']\n",
      "yessss\n",
      "['senior', 'data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['anti-financial', 'crime', '(afc)', 'anti-money', 'laundering', '(aml)', '–', 'data', 'scientist', '-', 'associate']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['machine', 'learning,', 'data', 'science', 'internship']\n",
      "['machine', 'learning', 'engineer']\n",
      "['research', 'analyst,', 'performance', 'management', 'design']\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['data', 'analyst', '(ny)']\n",
      "['quantitative', 'analysis,', 'winter', 'analyst', '(north', 'america', '-', '2019)']\n",
      "['data', '&', 'analysis', 'coordinator']\n",
      "['senior', 'data', 'scientist']\n",
      "yessss\n",
      "['data', 'strategy/machine', 'learning', 'ba']\n",
      "['sr', 'analyst,', 'data', '&', 'analysis']\n",
      "['data', 'analyst', '/', 'data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['intern', 'machine', 'learning', '&', 'design', 'research']\n",
      "['data', 'analysis', 'specialist']\n",
      "['senior', 'data', 'scientist', '-', 'nyc']\n",
      "yessss\n",
      "['data', 'engineer']\n",
      "['data', 'scientist,', 'innovation', 'lab']\n",
      "yessss\n",
      "['research', 'engineer,', 'ai', '(university', 'grad)']\n",
      "['gir,', 'data', 'strategist']\n",
      "['data', 'scientist,', 'accounting']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['gir,', 'data', 'strategist']\n",
      "['senior', 'data', 'scientist,', 'experimentation', 'practice']\n",
      "yessss\n",
      "['data', 'scientist,', 'detection']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['data', '&', 'analysis', 'coordinator']\n",
      "['data', 'analyst', '-', 'user', 'research']\n",
      "['senior', 'data', 'scientist']\n",
      "yessss\n",
      "['data', 'engineer']\n",
      "['data', 'scientist', 'midlevel']\n",
      "yessss\n",
      "['data', 'scientist', 'ii', '(forecasting', '&', 'scheduling)']\n",
      "yessss\n",
      "['data', 'scientist,', 'content']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['enterprise', 'data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['research', 'analyst,', 'people', 'analytics']\n",
      "['data', 'scientist', 'iii']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist', '–', 'content', 'marketing', 'engagement']\n",
      "yessss\n",
      "['audience', 'data', 'analyst']\n",
      "['data', 'scientist', '/', 'engineer']\n",
      "yessss\n",
      "['senior', 'data', 'scientist,', 'advanced', 'marketing', 'analytics']\n",
      "yessss\n",
      "['data', 'engineer']\n",
      "['research', 'scientist,', 'machine', 'learning', 'and', 'intelligence']\n",
      "['rankings', 'data', 'reporter']\n",
      "['data', 'scientist', 'technical', 'lead,', 'google', 'maps']\n",
      "yessss\n",
      "['data', 'engineering', 'manager,', 'analytics', '(instagram)']\n",
      "['technical', 'trainer,', 'data', 'and', 'machine', 'learning,', 'google', 'cloud']\n",
      "['data', 'scientist,', 'redtech']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['data', 'engineer', '-', 'machine', 'learning']\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['senior', 'data', 'scientist']\n",
      "yessss\n",
      "['data', 'science', '-', 'underwriting', 'analytics']\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['sr.', 'data', 'scientist']\n",
      "yessss\n",
      "['process', 'data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist', '(nyc)']\n",
      "yessss\n",
      "['enterprise', 'data', 'scientist']\n",
      "yessss\n",
      "['sr.', 'associate,', 'data', 'scientist,', 'machine', 'learning']\n",
      "yessss\n",
      "['senior', 'data', 'scientist,', 'product', '(free)']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['sr.', 'data', 'engineer']\n",
      "['data', 'scientist', 'iii']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['computational', 'scientist']\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['venture', 'capital', 'analyst', '-', 'data', 'scientist']\n",
      "yessss\n",
      "['principal', 'data', 'scientist']\n",
      "yessss\n",
      "['neuroradiology', 'scientist']\n",
      "['data', 'scientist', '-', 'bomoda']\n",
      "yessss\n",
      "['data', 'analyst']\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['chief', 'data', 'scientist', '-', 'financial', 'services']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['data', 'analyst']\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['principal', 'data', 'scientist']\n",
      "yessss\n",
      "['cimd', '-', 'consumer', 'finance', '-', 'decision', 'and', 'data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['head', 'of', 'data', 'science', 'controls']\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['data', 'solutions', 'consultant,', 'emerging', 'products']\n",
      "['intern', '-', 'ai', '&', 'machine', 'learning', 'ar', 'vr', 'coding']\n",
      "['lead', 'data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['data', 'engineer']\n",
      "['audience', 'data', 'analyst']\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['senior', 'data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['internet', 'and', 'technology', 'analyst', '-', 'executive', 'division,research', 'and', 'analytics', 'department', '(nyc)']\n",
      "['ibm', 'marketing', 'phd', 'data', 'scientist', 'intern,', 'summer', '2019']\n",
      "yessss\n",
      "['sr.', 'data', 'scientist']\n",
      "yessss\n",
      "['senior', 'data', 'scientist,', 'experimentation', 'practice']\n",
      "yessss\n",
      "['senior', 'strategic', 'analyst', '/', 'data', 'scientist']\n",
      "yessss\n",
      "['market', 'research', 'analyst']\n",
      "['data', 'science', 'analyst']\n",
      "['intern,', 'machine', 'learning']\n",
      "['data', 'science', 'intern', '-', 'engagement']\n",
      "['sr.', 'predictive', 'data', 'scientist', '4']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['lead', 'data', 'scientist']\n",
      "yessss\n",
      "['data', 'engineer-xsp']\n",
      "['cimd', '-', 'consumer', 'finance', '-', 'decision', 'and', 'data', 'scientist']\n",
      "yessss\n",
      "['instagram', '-', 'software', 'engineer,', 'machine', 'learning']\n",
      "['associate', 'director,', 'lead', 'data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['quantitative', 'researcher,', 'marketing', 'science', 'research']\n",
      "['analytics', 'expert', '-', 'journey', 'analytics,', 'new', 'ventures']\n",
      "['people', 'analytics', 'data', 'scientist', '-', 'human', 'capital', 'consulting']\n",
      "yessss\n",
      "['ibm', 'marketing', 'phd', 'data', 'scientist', 'intern,', 'summer', '2019']\n",
      "yessss\n",
      "['data', 'scientist', '-', 'investment', 'research']\n",
      "yessss\n",
      "['senior', 'analyst,', 'data', 'scientist']\n",
      "yessss\n",
      "['alphastudio', 'data', 'science', 'intern']\n",
      "['intern,', 'data', 'science', '-', 'part-time']\n",
      "['ecommerce', 'data', 'reporting', 'analyst']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['machine', 'learning', 'engineer']\n",
      "['senior', 'data', 'scientist', '-', 'chief', 'analytics', 'office']\n",
      "yessss\n",
      "['data', 'scientist', '-', 'investment', 'research']\n",
      "yessss\n",
      "['machine', 'learning', 'engineer']\n",
      "['data', 'scientist,', 'finance']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['museum', 'scientist', '2']\n",
      "['data', 'scientist', 'technical', 'lead,', 'google', 'maps']\n",
      "yessss\n",
      "['data', 'scientist,', 'engagement']\n",
      "yessss\n",
      "['custom', 'insights,', 'research', 'analyst']\n",
      "['sr.', 'data', 'engineer']\n",
      "['data', 'scientist', '–', 'content', 'marketing', 'engagement']\n",
      "yessss\n",
      "['data', 'strategy', 'analyst']\n",
      "['lead', 'data', 'scientist']\n",
      "yessss\n",
      "['applied', 'scientist', '-', 'question', 'answering']\n",
      "['sr.', 'data', 'scientist', '-', 'worldwide', 'public', 'sector', 'team']\n",
      "yessss\n",
      "['svp', '–', 'data', 'scientist', 'lead']\n",
      "yessss\n",
      "['quantitative', 'analyst']\n",
      "['analytics', 'consultant']\n",
      "['data', 'scientist', 'summer', 'intern']\n",
      "yessss\n",
      "['statistical', 'research', 'and', 'data', 'science', 'intern']\n",
      "['national', 'research', 'analyst']\n",
      "['quantitative', 'analyst']\n",
      "['senior', 'strategic', 'analyst', '/', 'data', 'scientist']\n",
      "yessss\n",
      "['research', 'scientist,', 'google', 'brain', '(united', 'states)']\n",
      "['junior', 'data', 'scientist']\n",
      "yessss\n",
      "['lead', 'data', 'scientist']\n",
      "yessss\n",
      "['staff', 'scientist', '(entry', 'level)']\n",
      "['data', 'scientist', 'intern']\n",
      "yessss\n",
      "['senior', 'associate,', 'data', 'scientist']\n",
      "yessss\n",
      "['principal', 'associate,', 'data', 'scientist']\n",
      "yessss\n",
      "['senior', 'data', 'scientist', '–', 'refinitiv', 'labs,', 'new', 'york', 'city']\n",
      "yessss\n",
      "['data', 'analyst']\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['research', 'scientist', '(ai)']\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['research', 'analyst,', 'latin', 'america', 'and', 'the', 'caribbean', 'country', 'analysis']\n",
      "['quantitative', 'analyst', '-', 'financial', 'resource', 'management']\n",
      "['manager,', 'data', '&', 'analytics', 'modeler', '-', 'machine', 'learning']\n",
      "['marketing', 'data', 'scientist', 'intern']\n",
      "yessss\n",
      "['data', 'research', 'and', 'acceleration', 'analyst']\n",
      "['data', 'engineer']\n",
      "['vp,', 'research', 'and', 'insights']\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist', '-', 'econometrics']\n",
      "yessss\n",
      "['quantitative', 'analyst,', 'advanced', 'data', '&', 'analytics']\n",
      "['research', 'data', 'associate']\n",
      "['brm', 'quantitative', 'analyst/developer']\n",
      "['principal,', 'data', 'science']\n",
      "['workforce', 'planning', '&', 'analytics', 'data', 'scientist,', 'internal', 'communications']\n",
      "yessss\n",
      "['antibiotic', 'resistance', 'data', 'analyst,', 'bureau', 'of', 'communicable', 'diseases']\n",
      "['data', 'analyst', '-', 'user', 'research']\n",
      "['data', 'reporter']\n",
      "['research', 'scientist']\n",
      "['multiplatform', 'research', 'analyst,', 'consumer', 'experience']\n",
      "['lead', 'data', 'scientist,', 'analytic', 'capabilities']\n",
      "yessss\n",
      "['data', 'science', 'internship']\n",
      "['city', 'research', 'scient', '03']\n",
      "['director,', 'data', 'scientist.', 'nlp']\n",
      "yessss\n",
      "['research', 'scientist', '4,', 'central', 'office;']\n",
      "['research', 'scientist,', 'optics']\n",
      "['head', 'of', 'data', 'solutions']\n",
      "['research', 'scientist,', 'cca']\n",
      "['analyst,', 'research']\n",
      "['city', 'research', 'scient', '03']\n",
      "['admitting', 'representative', '-', 'sunday,', '6am-2pm', '-', '7', 'hours']\n",
      "['senior', 'scientist,', 'oncological', 'sciences']\n",
      "['departmental', 'administrator']\n",
      "['senior', 'data', 'scientist']\n",
      "yessss\n",
      "['data', 'engineer']\n",
      "['statistical', 'analyst', '(contractor)']\n",
      "['summer', 'college', 'intern']\n",
      "['lead', 'data', 'scientist']\n",
      "yessss\n",
      "['departmental', 'administrator']\n",
      "['lead', 'data', 'scientist,', 'analytic', 'capabilities']\n",
      "yessss\n",
      "['senior', 'data', 'scientist,', 'product', '(free)']\n",
      "yessss\n",
      "['cimd', '-', 'consumer', 'finance', '-', 'decision', 'and', 'data', 'scientist']\n",
      "yessss\n",
      "['senior', 'data', 'analyst']\n",
      "['workforce', 'planning', '&', 'analytics', 'data', 'scientist,', 'internal', 'communications']\n",
      "yessss\n",
      "['quantitative', 'analyst,', 'ph.d.', 'intern']\n",
      "['machine', 'learning', 'engineer']\n",
      "['research', 'scientist', '(ai)']\n",
      "['analyst,', 'data', 'management', '&', 'quantitative', 'analysis']\n",
      "['statistical', 'analyst', '(contractor)']\n",
      "['policy', 'and', 'data', 'analyst']\n",
      "['lead', 'data', 'scientist']\n",
      "yessss\n",
      "['city', 'research', 'scient', '03']\n",
      "['computational', 'scientist']\n",
      "['associate', 'director,', 'lead', 'data', 'scientist']\n",
      "yessss\n",
      "['data', 'science', '&', 'advanced', 'analytics', 'senior', 'associate']\n",
      "['gsam', 'technology', '-', 'equities,', 'research', '&', 'qis', '-', 'imd', 'search', 'and', 'machine', 'learning', 'engineer']\n",
      "['data', 'scientist,', 'content']\n",
      "yessss\n",
      "['data', 'science', 'manager']\n",
      "['quantitative', 'analyst', '-', 'financial', 'resource', 'management']\n",
      "['data', 'scientist,', 'choice']\n",
      "yessss\n",
      "['machine', 'learning', 'engineer']\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['senior', 'data', 'scientist,', 'innovation', 'strategy']\n",
      "yessss\n",
      "['head', 'of', 'data', 'solutions']\n",
      "['data', 'solutions', 'consultant,', 'emerging', 'products']\n",
      "['cimd', '-', 'consumer', 'finance', '-', 'decision', 'and', 'data', 'scientist']\n",
      "yessss\n",
      "['distribution', 'attendant']\n",
      "['program', 'associate', 'ivf']\n",
      "['data', 'center', 'technician']\n",
      "['clinical', 'data', 'standards', 'analyst']\n",
      "['gir,', 'data', 'strategist']\n",
      "['scientist', 'ii']\n",
      "['data', 'strategy', 'analyst']\n",
      "['applied', 'scientist', '-', 'question', 'answering']\n",
      "['fgp', 'sec', 'i-intake/sched', 'per', 'diem', 'ivf']\n",
      "['oace-001-modeling', 'and', 'data', 'analysis', 'intern']\n",
      "['program', 'analytics', '/', 'data', 'analysis', 'manager']\n",
      "['portfolio', 'scientist']\n",
      "['financial', 'data', 'coordinator']\n",
      "['facilities', 'intern']\n",
      "['data', 'strategy', 'analyst']\n",
      "['core', 'engineering', '-', 'data', 'intelligence', '-', 'machine', 'learning', '(ml)', 'scientists', 'and', 'ml', 'engineers']\n",
      "['program', 'associate', 'ivf']\n",
      "['program', 'associate', 'ivf']\n",
      "['clinical', 'interviewer']\n",
      "['bellagio/events', 'assistant']\n",
      "['patient', 'care', 'assistant', '(40)']\n",
      "['senior', 'statistical', 'clerk']\n",
      "['fgp', 'sec', 'i-intake/sched', '(35)', '*astoria*', '(shift', 'btwn', '9:30-6pm', 'alt', 'sats)']\n",
      "['research', 'analyst,', 'advertiser', 'measurement']\n",
      "['senior', 'associate,', 'data', 'scientist']\n",
      "yessss\n",
      "['research', 'analyst,', 'latin', 'america', 'and', 'the', 'caribbean', 'country', 'analysis']\n",
      "['data', 'engineer']\n",
      "['data', 'engineer']\n",
      "['research', 'data', 'associate']\n",
      "['data', 'scientist', '/', 'engineer']\n",
      "yessss\n",
      "['manager,', 'insights', '&', 'analytics']\n",
      "['senior', 'data', 'scientist', '–', 'refinitiv', 'labs,', 'new', 'york', 'city']\n",
      "yessss\n",
      "['quantitative', 'social', 'scientist']\n",
      "['sr.', 'associate,', 'data', 'scientist']\n",
      "yessss\n",
      "['senior', 'data', 'scientist', '-', 'machine', 'learning', '/', 'nlp']\n",
      "yessss\n",
      "['quantitative', 'analyst', 'm/f', '-', 'vie', 'new', 'york']\n",
      "['vp,', 'research', 'and', 'insights']\n",
      "['data', 'engineer', '-', 'value', 'models']\n",
      "['senior', 'data', 'scientist']\n",
      "yessss\n",
      "['gsam', 'technology', '-', 'equities,', 'research', '&', 'qis', '-', 'imd', 'search', 'and', 'machine', 'learning', 'engineer']\n",
      "['developmental', 'intern', '-', 'data', 'integration']\n",
      "['senior', 'data', 'scientist,', 'innovation', 'strategy']\n",
      "yessss\n",
      "['staff', 'machine', 'learning', 'engineer', '–', 'free', 'mission']\n",
      "['senior', 'data', 'scientist']\n",
      "yessss\n",
      "['software', 'engineer,', 'machine', 'learning']\n",
      "['data', 'and', 'technology', 'analyst,', 'bureau', 'of', 'emergency', 'field', 'operations']\n",
      "['user', 'experience', 'designer', '(data', 'visualization', 'focus)']\n",
      "['behavioral', 'scientist']\n",
      "['customer', 'data', 'management', 'senior', 'analyst']\n",
      "['ops', 'research', 'engineer/data', 'scientist']\n",
      "['sr', 'research', 'scientist']\n",
      "['associate,', 'artificial', 'intelligence', '&', 'machine', 'learning']\n",
      "['fgp', 'billing', 'rep', '(35)']\n",
      "['data', 'scientist', 'and', 'quantitative', 'dev', 'lead']\n",
      "yessss\n",
      "['program', 'associate,', 'bellagio', '&', 'fellowships']\n",
      "['materials', 'science', 'support', 'scientist']\n",
      "['analytics', 'intern']\n",
      "['research', 'director', '–', 'machine', 'learning']\n",
      "['senior', 'analyst', '-', 'quantitative', 'modeling']\n",
      "['core', 'engineering', '-', 'data', 'intelligence', '-', 'machine', 'learning', '(ml)', 'scientists', 'and', 'ml', 'engineers']\n",
      "['program', 'analytics', '/', 'data', 'analysis', 'manager']\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['ad', 'products', 'operations', 'analyst']\n",
      "['global', 'marketplace', 'quantitative', 'analytics', 'associate']\n",
      "['senior', 'manager,', 'data', 'scientist']\n",
      "yessss\n",
      "['quantitative', 'analyst', 'm/f', '-', 'vie', 'new', 'york']\n",
      "['junior', 'research', 'scientist']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fusion', 'center', '–', 'data', 'derived', 'threat', 'intelligence', 'manager', '(svp)']\n",
      "['museum', 'scientist', '2,', 'box', 'oce-1115/28103']\n",
      "['data', 'engineer']\n",
      "['fgp', 'medical', 'secretary', '(35)']\n",
      "['scientist,', 'thermosets', 'and', 'additives']\n",
      "['research', 'scientist,', 'google', 'brain', '(united', 'states)']\n",
      "['assistant', 'scientist', '-', 'night', 'shift']\n",
      "['machine', 'learning', 'research', 'scientist']\n",
      "['fgp', 'sec', 'i-intake/sched', '(35)', '*astoria*', '(shift', 'btwn', '9:30-6pm', 'alt', 'sats)']\n",
      "['senior', 'statistical', 'clerk']\n",
      "['investment', 'research', 'analyst']\n",
      "['data', 'engineer']\n",
      "['senior', 'business', 'intelligence', 'engineer', '/', 'data', 'analyst']\n",
      "['data', 'engineer', '-', 'analytics']\n",
      "['biotel', 'research', '-', 'data', 'analyst']\n",
      "['marketing', '&', 'service', 'data', 'scientist', '-', 'vice', 'president']\n",
      "yessss\n",
      "['quantitative', 'researcher', '-', 'internship', \"(bachelor's/master's)\"]\n",
      "['database', 'analyst']\n",
      "['senior', 'analyst', '-', 'quantitative', 'modeling']\n",
      "['policy', 'and', 'data', 'analyst']\n",
      "['research', 'analyst']\n",
      "['research', 'staff', '-', 'institute', 'for', 'data', 'exploration', 'and', 'applications']\n",
      "['sql', 'developer']\n",
      "['machine', 'learning', 'engineer']\n",
      "['ibm', 'communications', 'intern,', 'summer', '2019']\n",
      "['senior', 'data', 'research', 'analyst']\n",
      "['research', 'staff,', 'darrin', 'freshwater', 'institute']\n",
      "['machine', 'learning', 'engineer']\n",
      "['senior', 'data', 'scientist,', 'product']\n",
      "yessss\n",
      "['sr', 'quantitative', 'finance', 'analyst']\n",
      "['sr', 'quantitative', 'finance', 'analyst']\n",
      "['machine', 'learning', 'engineer']\n",
      "['data', 'scientist']\n",
      "yessss\n",
      "['city', 'research', 'scient', '03']\n",
      "['city', 'research', 'scient', '03']\n",
      "['global', 'markets', 'summer', 'analyst,', 'quantitative', 'trading', 'and', 'research-', '2020']\n",
      "['senior', 'data', 'scientist']\n",
      "yessss\n",
      "['research', 'scientist', '(ai)']\n",
      "['chief', 'data', 'scientist', '-', 'financial', 'services']\n",
      "yessss\n",
      "['research', 'worker']\n",
      "['research', 'assistant']\n",
      "['research', 'scientist,', 'machine', 'learning', 'and', 'intelligence']\n",
      "['rankings', 'data', 'reporter']\n",
      "['scientist,', 'icp']\n",
      "['quantitative', 'analyst,', 'advanced', 'data', '&', 'analytics']\n",
      "['research', 'analyst']\n",
      "['statistical', 'programmer/data', 'manager', '-', 'general', 'medicine']\n",
      "['geologist', 'i,', 'engineer', 'i', 'or', 'scientist', 'i']\n",
      "['operations', 'associate']\n",
      "['quality', 'control', 'scientist']\n",
      "['quantitative', 'analyst,', 'ph.d.', 'intern']\n",
      "['big', 'data', 'engineer']\n",
      "['manager,', 'insights', '&', 'analytics']\n",
      "['ccbd', 'technology', '-', 'machine', 'learning', 'data', 'engineer']\n",
      "['senior', 'user', 'researcher', '–', 'growth']\n",
      "['visiting', 'scientist', '(ai)']\n",
      "['machine', 'learning', 'engineer']\n",
      "['quantitative', 'researcher', '-', 'internship', '(phd)']\n",
      "['data', 'science', 'engineer']\n",
      "['data', '&', 'platform', 'engineer']\n",
      "['software', 'engineer', '-', 'machine', 'learning,', 'uber', 'eats']\n",
      "['quantitative', 'analyst,', 'ph.d.', 'intern']\n",
      "['admitting', 'representative', '-', 'm-f,', '4pm-12am', '-', '35', 'hours']\n",
      "['data', 'engineer', '–', 'legal', '&', 'licensing']\n",
      "['machine', 'learning', 'research', 'scientist']\n",
      "['attribution', 'ad', 'sales', 'research', 'analyst']\n",
      "['analyst,', 'digital', 'research', '&', 'consumer', 'intelligence']\n",
      "['product', 'insights', 'manager,', 'advertising', 'experience']\n",
      "['research', 'staff', 'member']\n",
      "['data', 'engineer-xsp']\n",
      "['research', 'position', '(various', 'levels),', 'systems', 'biology']\n",
      "['research', 'analyst']\n",
      "['fusion', 'center', '–', 'data', 'derived', 'threat', 'intelligence', 'manager', '(svp)']\n",
      "['training', 'manager', '-', 'applied', 'data', 'analytics']\n",
      "['database', 'analyst']\n",
      "['software', 'engineer', '-', 'data']\n",
      "['data', 'engineering', 'manager,', 'customer', 'insights']\n",
      "['senior', 'data', 'scientist,', 'product']\n",
      "yessss\n",
      "['senior', 'data', 'engineer', '-', 'analytics']\n",
      "['quantitative', 'risk', 'analyst,', 'vice', 'president']\n",
      "['fgp', 'medical', 'secretary', '(35)']\n",
      "['fulltime', 'temporary', 'secretary', 'ii']\n",
      "['quantitative', 'analyst', 'm/f', '-', 'vie', 'new', 'york']\n",
      "['fgp', 'sec', 'i-intake/scheduler,', '**', 'huntington,', 'long', 'island']\n",
      "['research', 'scientist']\n",
      "['research', 'scientist']\n",
      "['senior', 'data', 'scientist,', 'product', 'analytics']\n",
      "yessss\n",
      "['data', 'science', 'online', 'project', 'instructor', '(part-time,', 'contract)']\n",
      "['secretary', 'ii']\n",
      "['geologist/environmental', 'scientist']\n",
      "['staff', 'scientist,', 'quantitative', 'pharmacology']\n",
      "['credit', 'research', 'analyst']\n",
      "['ops', 'research', 'engineer/data', 'scientist']\n",
      "['systems', 'intern', '(opensource', 'developer)']\n",
      "['director', 'of', 'data', 'science']\n",
      "['data', 'strategy', 'analyst']\n",
      "['staff', 'backend', 'engineer,', 'machine', 'learning', '–', 'free', 'mission']\n",
      "['data', 'scientist', 'manager', '-', 'new', 'york!']\n",
      "yessss\n",
      "['data', 'engineer', '-', 'analytics']\n",
      "['security', 'data', 'scientist']\n",
      "yessss\n",
      "['machine', 'learning', 'research', 'scientist']\n",
      "['senior', 'manager,', 'data', 'engineering', '(center', 'for', 'machine', 'learning)']\n",
      "['software', 'engineer,', 'internship']\n",
      "['data', 'scientist', '-', 'senior', 'consultant', '-', 'new', 'york']\n",
      "yessss\n",
      "['marketing', '&', 'service', 'data', 'scientist', '-', 'vice', 'president']\n",
      "yessss\n",
      "['research', 'analyst']\n",
      "['data', 'scientist', '-', 'nlp', 'expert']\n",
      "yessss\n",
      "['senior', 'quantitative', 'analyst', 'in', 'model', 'validation']\n",
      "['analytics', 'consultant,', 'decision', 'analytics']\n",
      "['accenture', 'strategy', '-', 'enterprise', 'analytics', 'manager']\n",
      "['quality', 'improvement', 'research', 'analyst', '-', 'surgery']\n",
      "['data', 'engineer', 'cvp-', 'center', 'of', 'data', 'science', 'team']\n",
      "['postdoctoral', 'fellows,', 'software', 'engineers,', 'or', 'graduate', 'sudents', 'in', 'data', 'integration,', 'online', 'simulation,', 'and', 'visualization']\n",
      "['research', 'product', 'analyst']\n",
      "['analyst,', 'marketing', 'science']\n",
      "['research', 'analyst,', 'stamford', '&', 'nyc']\n",
      "['data', 'communications', 'research', 'manager']\n",
      "['quantitative', 'software', 'developer']\n",
      "['applied', 'scientist', '-', 'amazon', 'ai']\n",
      "['lead', 'data', 'scientist']\n",
      "yessss\n",
      "['portfolio', 'servicing', 'analyst']\n",
      "['senior', 'research', 'analyst']\n",
      "['fgp', 'sec', 'i-intake/sched', '(40)']\n",
      "['research', 'intern', '-', 'microsoft', 'research', 'fate', '&', 'microsoft', 'office']\n",
      "['director', 'of', 'data', 'analytics']\n",
      "['data', 'scientist', '-', 'senior', 'consultant', '-', 'new', 'york']\n",
      "yessss\n",
      "['research', 'analyst']\n",
      "['junior', 'technical', 'business', 'analyst']\n",
      "['research', 'scientist,', 'phd', 'university', 'grad', '(systems', 'and', 'infrastructure)', '(2019)']\n",
      "['research', 'analyst']\n",
      "['principal', 'engineer,', 'data', 'science,', 'audience', 'studio']\n",
      "['sr', 'analyst-', 'report', 'developer']\n",
      "['data', 'engineer']\n",
      "['data', 'engineer']\n",
      "['lead', 'data', 'engineer']\n",
      "['associate', 'director,', 'data', 'science']\n",
      "['senior', 'data', 'engineer']\n",
      "['senior', 'data', 'engineer']\n",
      "['biotel', 'research', '-', 'data', 'analyst']\n",
      "['energy', 'analyst']\n",
      "['intern', '-', 'artificial', 'intelligence', '&', 'machine', 'learning']\n",
      "['new', 'audiences', 'editor']\n",
      "['research', 'staff', '-', 'institute', 'for', 'data', 'exploration', 'and', 'applications']\n",
      "['research', 'analyst']\n",
      "['research', 'scientist']\n",
      "['research', 'analyst']\n",
      "['sr', 'analyst,', 'primary', 'research']\n",
      "['associate', '-', 'machine', 'learning']\n",
      "['research', 'scientist,', 'speech', 'recognition', '(phd', 'student', 'or', 'grad)']\n",
      "['research', 'analyst']\n",
      "['research', 'scientist,', 'cca']\n",
      "['sr.', 'data', 'engineer']\n",
      "['statistical', 'programmer']\n",
      "['scientist', '-', 'mouse', 'phenotyping', 'and', 'disease', 'modeling', 'pipeline']\n",
      "['machine', 'learning', 'engineer']\n",
      "['analyst,', 'cross-platform', 'research']\n",
      "['museum', 'scientist', '2']\n",
      "['urban', 'analyst']\n",
      "['research', 'analyst,', 'stamford', '&', 'nyc']\n",
      "['associate', 'staff', 'scientist,', 'automation', 'systems']\n",
      "['young', 'audiences', 'editor']\n",
      "['analyst,', 'digital', 'research', '&', 'consumer', 'intelligence']\n",
      "['senior', 'analyst', '-', 'consumer', 'brand', 'research']\n",
      "['quantitative', 'research', 'associate']\n",
      "['fgp', 'ambulatory', 'practice', 'liaison-patient', 'experience']\n",
      "['research', 'director', '(health', '&', 'mental', 'health)']\n",
      "['part-time', 'research', 'data', 'associate']\n",
      "['analyst', 'research', 'statistics']\n",
      "['market', 'research', 'analyst']\n",
      "['machine', 'learning', 'cloud', 'consultant']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ml', 'software', 'engineer']\n",
      "['data', 'scientist', 'manager', '-', 'new', 'york!']\n",
      "yessss\n",
      "['machine', 'learning', 'engineer']\n",
      "['senior', 'analytics', 'consultant,', 'decision', 'analytics']\n",
      "['senior', 'data', 'scientist', '-', 'machine', 'learning', '/', 'nlp']\n",
      "yessss\n",
      "['machine', 'learning', 'engineer']\n",
      "['machine', 'learning', 'engineer']\n",
      "['offering', 'manager']\n",
      "['data', 'science', 'manager']\n",
      "['ai', 'research', 'scientist', '-', 'nlp']\n",
      "['equity', 'research', '-', 'medical', 'devices', 'analyst', '/', 'associate']\n",
      "['ecommerce', 'full', 'stack', 'engineer']\n",
      "['senior', 'data', 'scientist']\n",
      "yessss\n",
      "['data', 'engineer']\n",
      "['temp', '-', 'biostatistician']\n",
      "['principal', 'decision', 'scientist', '(decision', 'engineering)']\n",
      "['data', 'strategy/machine', 'learning', 'architect,', 'vp', '(']\n",
      "['product', 'manager,', 'instagram', 'home', 'ranking']\n",
      "['senior', 'data', 'scientist']\n",
      "yessss\n",
      "['algo', 'trading', 'model', 'validation', 'quantitative', 'analyst']\n",
      "['research', 'analyst']\n",
      "['programmer']\n",
      "['research', 'scientist', '(ai)', '(us)', '(industry)']\n",
      "['manager', 'of', 'data', 'science-', 'machine', 'learning']\n",
      "['quantitative', 'analyst']\n",
      "['product', 'manager,', 'instagram', 'home', 'ranking']\n",
      "['senior', 'data', 'scientist,', 'analytics', 'lab', 'team']\n",
      "yessss\n",
      "['software', 'engineer,', 'machine', 'learning']\n",
      "['market', 'impact', 'quantitative', 'analyst']\n",
      "['senior', 'data', 'science', 'quant', 'developer']\n",
      "['analyst,', 'equity', 'research']\n",
      "['opportunities', 'in', 'semantic', 'technologies', 'research']\n",
      "['director,', 'data', '&', 'analytics']\n",
      "['research', 'analyst', '-', 'apex', 'credit', 'partners']\n",
      "['quantitative', 'analyst', 'fintech', 'investments', '–', 'avp', '|', 'vp']\n",
      "['head', 'of', 'data', 'science', 'controls']\n",
      "['assoc.', 'dir.,', 'data', 'science']\n",
      "['corporate', 'finance', '–', 'turnaround', '&', 'restructuring']\n",
      "['associate', 'librarian,', 'data', 'management', 'services']\n",
      "['quantitative', 'researcher', '-', 'internship', '(phd)']\n",
      "['machine', 'learning', 'engineer']\n",
      "['product', 'analyst']\n",
      "['systems', 'interface', 'analyst']\n",
      "['research', 'scientist', '1', '/', 'eoa#', '2019-12']\n",
      "['research', 'scientist']\n",
      "['senior', 'data', 'engineer']\n",
      "['senior', 'data', 'engineer']\n",
      "['principal', 'research', 'scientist']\n",
      "['global', 'manager,', 'data', 'integration']\n",
      "['museum', 'scientist', '2']\n",
      "['scientific', 'associate', 'or', 'engineer', '-', 'data', 'acquisition', 'systems', '(entry', 'level)']\n",
      "['carbon', 'reduction', 'strategist']\n",
      "['corporate', 'finance', '–', 'turnaround', '&', 'restructuring']\n",
      "['analyst,', 'equity', 'research']\n",
      "['quantitative', 'researcher', '-', 'internship', '(phd)']\n",
      "['market', 'research', 'analyst']\n",
      "['project', 'coordinator']\n",
      "['applied', 'scientist,', 'alexa', 'ai']\n",
      "['research', 'position', '(various', 'levels),', 'neuroscience']\n",
      "['market', 'impact', 'quantitative', 'analyst']\n",
      "['hedge', 'fund', 'research', 'analyst']\n",
      "['senior', 'streaming', 'data', 'engineer', '(flink', '&', 'kafka)']\n",
      "['opportunities', 'in', 'semantic', 'technologies', 'research']\n",
      "['director', 'of', 'data', 'science']\n",
      "['behavioral', 'data', 'scientist', '-', 'ipsos', 'behavioral', 'data', 'group']\n",
      "yessss\n",
      "['sr.', 'machine', 'learning', 'engineer', '–', 'content', 'knowledge']\n",
      "['senior', 'data', 'engineer']\n",
      "['ai', 'research', 'scientist']\n",
      "['research', 'engineer', '-', 'video', 'intelligence', 'machine', 'learning', 'services']\n",
      "['market', 'research', 'analyst']\n",
      "['market', 'research', 'analyst']\n",
      "['machine', 'learning', 'engineer']\n",
      "['wsj', 'newsroom', 'innovation', 'chief']\n",
      "['senior', 'research', 'analyst']\n",
      "['quantitative', 'finance', 'analyst']\n",
      "['research', 'scientist', '1', '/', 'eoa#', '2019-12']\n",
      "['operations', 'analyst', '-', 'cancer', 'center']\n",
      "['analyst,', 'sales', 'research']\n",
      "['business', 'intelligence', 'developer']\n",
      "['product', 'analyst']\n",
      "['attribution', 'ad', 'sales', 'research', 'analyst']\n",
      "['biotel', 'research', '-', 'data', 'analyst']\n",
      "['fgp', 'sec', 'ii-intake/sched-', 'radiology']\n",
      "['associate', 'business', 'analyst']\n",
      "['programmatic', 'specialist']\n",
      "['policy', 'advisor']\n",
      "['research', 'scientist', '(ai)']\n",
      "['study', 'coordinator']\n",
      "['senior', 'associate,', 'data', 'engineering']\n",
      "['project', 'assistant']\n",
      "['bi', 'developer']\n",
      "['admitting', 'representative', '-', 'sunday,', '6am-2pm', '-', '7', 'hours']\n",
      "['tumblr:', 'principal', 'data', 'infrastructure', 'engineer']\n",
      "['software', 'engineer,', 'data', 'science', '/', 'real', 'time', 'platform', '(java,', 'kafka,', 'streaming', 'data)']\n",
      "['equity', 'research', 'analyst', '–', 'long', 'only', '–', 'natural', 'resources']\n",
      "['reporter,', 'multiple', 'mediums']\n",
      "['senior', 'strategy', 'consultant']\n",
      "['senior', 'data', 'scientist', '/', 'engineer']\n",
      "yessss\n",
      "['part-time', 'program', 'associate', '(28)']\n",
      "['machine', 'learning', 'engineer']\n",
      "['machine', 'learning', 'engineer']\n",
      "['sql', 'developer']\n",
      "['operations', 'research', 'analyst']\n",
      "['project', 'administrator']\n",
      "['data', 'integrity', 'analyst/', 'bureau', 'of', 'mental', 'health']\n",
      "['senior', 'digital', 'analyst']\n",
      "['geologist/environmental', 'scientist', '-', 'junior', 'to', 'mid', 'level']\n",
      "['research', 'software', 'engineer']\n",
      "['global', 'planning', 'and', 'research', 'analyst']\n",
      "['director', 'of', 'client', 'experience']\n",
      "['senior', 'full', 'stack', 'developer,', 'data', 'science', '-', 'refinitiv', 'labs']\n",
      "['national', 'research', 'analyst']\n",
      "['specialist', 'director,', 'machine', 'learning,', 'data', 'scientist']\n",
      "yessss\n",
      "['data', 'engineer,', 'real', 'estate', 'and', 'development', 'technology']\n",
      "['senior', 'big', 'data', 'etl', 'developer']\n",
      "['director,', 'data', 'science', '–', 'machine', 'learning,', 'big', 'data,', 'data', 'mining']\n",
      "['ibm', 'summer', '2019', 'marketing', 'mba/masters', 'intern']\n",
      "['research', 'analyst,', 'senior']\n",
      "['principal', 'data', 'scientist', '-', 'marketing', 'analytics,', 'advanced', 'modeling']\n",
      "yessss\n",
      "['data', 'science', 'online', 'project', 'instructor', '(part-time,', 'contract)']\n",
      "['scientist', 'i']\n",
      "['computer', 'vision', '/', 'machine', 'learning', 'engineer', '-', 'jadak']\n",
      "['program', 'associate', 'ivf']\n",
      "['opportunities', 'in', 'semantic', 'technologies', 'research']\n",
      "['director,', 'data', 'science']\n",
      "['senior', 'research', 'analyst']\n",
      "['senior', 'associate,', 'data', 'engineering']\n",
      "['statistical', 'programmer-', 'general', 'medicine']\n",
      "['precision', 'medicine', '-', 'quantitative', 'translational', 'scientist']\n",
      "['data', '&', 'platform', 'engineer']\n",
      "['senior', 'applied', 'scientist']\n",
      "['part-time', 'research', 'data', 'associate']\n",
      "['database', 'analyst']\n",
      "['director', 'of', 'data', 'science']\n",
      "['senior', 'investment', 'writer']\n",
      "['project', 'assistant']\n",
      "['ecommerce', 'business', 'intelligence', 'specialist']\n",
      "['associate,', 'planning']\n",
      "['data', 'architect', 'manager']\n",
      "['data', '&', 'platform', 'engineer']\n",
      "['associate', 'director,', 'data', 'science']\n",
      "['subject', 'matter', 'expert', 'construction,', 'collaboration', '&', 'data', 'management']\n",
      "['credit', 'research', 'analyst']\n",
      "['data', '&', 'platform', 'engineer']\n",
      "['technical', 'trainer,', 'data', 'and', 'machine', 'learning,', 'google', 'cloud']\n",
      "['senior', 'data', 'scientist', '/', 'engineer']\n",
      "yessss\n",
      "['engineering', 'manager', 'data', 'science']\n",
      "['summer', 'intern', '-', 'copywriter']\n",
      "['statistical', 'programmer']\n",
      "['senior', 'associate', 'scientist', '–', 'viral', 'vaccines']\n",
      "['murex', 'quantitative/risk', 'analyst']\n",
      "['manager', 'of', 'data', 'science-', 'machine', 'learning']\n",
      "['algo', 'trading', 'model', 'validation', 'quantitative', 'analyst']\n",
      "['brm', 'quantitative', 'analyst/developer']\n",
      "['product', 'manager', '-', 'data', 'services', 'and', 'tools']\n",
      "['sr.', 'data', 'engineer']\n",
      "['environmental', '-', 'geologist,', 'scientist', 'or', 'engineer', '(entry-level)']\n",
      "['ecommerce', 'business', 'intelligence', 'specialist']\n",
      "['senior', 'engineer']\n",
      "['bus', 'intel', 'analyst', 'i']\n",
      "['fgp', 'patient', 'care', 'asst', '*hematology*', '(37.5)', 'lake', 'success', 'ny']\n",
      "['analytics', 'expert', '-', 'journey', 'analytics,', 'new', 'ventures']\n",
      "['developmental', 'intern', '-', 'environmental', 'operations']\n",
      "['fgp', 'sec', 'ii-intake/sched-', 'radiology']\n",
      "['senior', 'manager,', 'data', 'scientist']\n",
      "yessss\n",
      "['visiting', 'scientist', '(ai)']\n",
      "['laboratory', 'technician']\n",
      "['senior', 'laboratory', 'scientist']\n",
      "['statistical', 'programmer', 'analyst']\n",
      "['research', 'technician', 'a']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['senior', 'laboratory', 'scientist']\n",
      "['quantitative', 'analyst', '-', 'financial', 'resource', 'management']\n",
      "['analyst,', 'sales', 'research']\n",
      "['vacuum/mechanical', 'technician']\n",
      "['college', 'research', 'intern']\n",
      "['statistical', 'programmer']\n",
      "['undergraduate/graduate', 'data', 'analysis', 'and', 'research', 'internship', '(summer', '2019)']\n",
      "['part-time', 'assistant', 'research', 'scientist,', 'non-exempt', '(ercan', 'lab)']\n",
      "['data', 'vizualization', '&', 'user', 'exprience/ux', 'associate', '-', 'data', 'capabilities', 'office', '-', 'research', '&', 'statistics', 'group']\n",
      "['environmental', '-', 'geologist,', 'scientist', 'or', 'engineer', '(entry-level)']\n",
      "['junior', 'technical', 'business', 'analyst']\n",
      "['research', 'scientist']\n",
      "['senior', 'data', 'engineer']\n",
      "['machine', 'learning', 'modeling', 'engineer']\n",
      "['program', 'manager']\n",
      "['scientific', 'researcher', 'or', 'engineer', '-', 'data', 'acquisition', 'systems', '(experienced)']\n",
      "['quantitative', 'analyst,', 'associate/avp']\n",
      "['systems', 'and', 'reporting', 'manager']\n",
      "['murex', 'quantitative/risk', 'analyst']\n",
      "['associate', 'librarian,', 'data', 'management', 'services']\n",
      "['program', 'associate', '(grants)']\n",
      "['operations', 'engineer']\n",
      "['bioinformatics', 'analyst']\n",
      "['director', 'of', 'client', 'experience']\n",
      "['analytics', 'expert', '-', 'journey', 'analytics,', 'new', 'ventures']\n",
      "['quantitative', 'analyst', '-', 'cash', 'equity', 'strategies']\n",
      "['part-time', 'non-exempt', 'assistant', 'research', 'scientist']\n",
      "['associate', 'analyst,', 'media', 'research,', 'insights', 'and', 'analytics']\n",
      "['statistical', 'reporting', 'accountant']\n",
      "['senior', 'research', 'analyst']\n",
      "['part-time', 'program', 'associate', '(28)']\n",
      "['product', 'growth', 'associate']\n",
      "['research', 'analyst', 'human', 'capital']\n",
      "['staff', 'web', 'engineer,', 'infrastructure']\n",
      "['scientist,', 'analytical', 'assay', 'development']\n",
      "['analytics', 'consultant', 'ii', '(campus', 'recruitment', 'fall', '2018)']\n",
      "['director', '-', 'liquid', 'studios', 'new', 'york']\n",
      "['senior', 'manager', 'supplier', 'payments', 'strategy', 'and', 'analytics']\n",
      "['esg', 'research', 'analyst', '-', 'equity']\n",
      "['bioinformatics', 'programmer']\n",
      "['director', '-', 'crm']\n",
      "['sr.', 'data', 'engineer']\n",
      "['delivery', 'consultant']\n",
      "['global', 'marketplace', 'algorithms', 'associate']\n",
      "['informatica', 'engineer']\n",
      "['associate', 'director', '-', 'heor', 'strategy']\n",
      "['data', 'engineering', 'manager,', 'analytics', '(instagram)']\n",
      "['staff', 'engineer,', 'data']\n",
      "['content', 'specialist']\n",
      "['senior', 'scientist,', 'department', 'of', 'psychiatry']\n",
      "['senior', 'director,', 'attribution']\n",
      "['consultancy:', 'geospatial', 'lead,', 'magicbox,', 'ictd', 'new', 'york']\n",
      "['scientific', 'associate', '-', 'medical', 'writer']\n",
      "['analyst', '-', 'team', 'ibm', 'media']\n",
      "['environmental', 'scientist,', 'bureau', 'of', 'environmental', 'disease', 'and', 'injury', 'prevention']\n",
      "['machine', 'learning', 'engineering', 'intern']\n",
      "['market', 'research', 'analyst']\n",
      "['experienced', 'equities', 'quantitative', 'analyst']\n",
      "['nuclear', 'data', 'physicist']\n",
      "['strategic', 'research', 'analyst']\n",
      "['environmental', 'science', 'intern']\n",
      "['statistical', 'reporting', 'accountant']\n",
      "['market', 'research', 'analyst']\n",
      "['software', 'development', 'manager,', 'machine', 'learning']\n",
      "['senior', 'manager', 'supplier', 'payments', 'strategy', 'and', 'analytics']\n",
      "['ogiq', 'research', 'analyst']\n",
      "['senior', 'data', 'engineer']\n",
      "['research', 'software', 'engineer']\n",
      "['special', 'assistant,', 'office', 'of', 'the', 'commissioner']\n",
      "['research', 'analyst,', 'phocuswright']\n",
      "['principal', 'machine', 'learning', 'engineer']\n",
      "['analytics', 'consultant,', 'decision', 'analytics']\n",
      "['statistical', 'programmer', 'analyst']\n",
      "['technical', 'recruiter']\n",
      "['associate', 'research', 'coordinator']\n",
      "['sr', 'analyst-', 'report', 'developer']\n",
      "['distribution', 'attendant']\n",
      "['scientist,', 'immunology', '&', 'inflammation']\n",
      "['part-time', 'assistant', 'research', 'scientist,', 'non-exempt', '(ercan', 'lab)']\n",
      "['associate,', 'integrated', 'planning']\n",
      "['associate', 'financial', 'analyst', '(rco-outpatient)']\n",
      "['epic', 'cadence', 'analyst']\n",
      "['analyst,', 'equity', 'research']\n",
      "['part', 'time', 'non-exempt', 'assistant', 'research', 'scientist:']\n",
      "['portfolio', 'servicing', 'analyst']\n",
      "['fgp', 'sec', 'ii-intake/sched-floater']\n",
      "['research', 'intern']\n",
      "['bus', 'intel', 'analyst', 'i']\n",
      "['data', 'engineering', 'manager,', 'analytics', '(instagram)']\n",
      "['fgp', 'secretary', 'i-intake/scheduler', '(temp', 'program)']\n",
      "['assistant', 'manager,', 'decision', 'analytics', 'services']\n",
      "['bioinformatics', 'analyst']\n",
      "['senior', 'research', 'analyst', '-', 'new', 'york']\n",
      "['precision', 'medicine', '-', 'quantitative', 'translational', 'scientist']\n",
      "['director,', 'data', 'science', 'product', 'ops']\n",
      "['geologist', 'i,', 'engineer', 'i', 'or', 'scientist', 'i']\n",
      "['machine', 'learning', 'infrastructure', 'engineer']\n",
      "['medical', 'editor']\n",
      "['senior', 'scientist,', 'department', 'of', 'psychiatry']\n",
      "['senior', 'research', 'scientist']\n"
     ]
    }
   ],
   "source": [
    "query = [\"data+scientist\", 'data+analyst', 'data+engineer']\n",
    "location = [\"New+York\"]\n",
    "list_urls =[]\n",
    "\n",
    "for i in range(len(query)):\n",
    "    list_pos =[]\n",
    "    urls1 = get_urls('indeed',query[i], location)\n",
    "\n",
    "    list_urls.append(urls1)\n",
    "    print('length list urls', len(list_urls))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not in data scientist\n",
    "['real', 'world', 'data', 'scientist/epidemiologist']\n",
    "['decision', 'scientist']\n",
    "['applied', 'scientist', 'intern', '-', 'alexa', 'shopping']\n",
    "['fraud', 'scientist', 'engineer']\n",
    "['applied', 'scientist']\n",
    "['bi', 'team', 'leader']\n",
    "['senior', 'r&d/data', 'scientist']\n",
    "senior', 'r&d/data', 'scientist']\n",
    "['excellent', 'excel', 'command.']\n",
    "['data', 'science', '-', 'team', 'lead']\n",
    "['excellent', 'inter-personal,', 'communication', '&', 'teamwork', 'skills']\n",
    "how come this gets to be the title\n",
    "['head', 'of', 'data', 'science']\n",
    "['data', 'product', 'manager']\n",
    "['senior', 'applied', 'scientist', '-', 'alexa', 'shopping']\n",
    "['senior', 'security', 'data-scientist']\n",
    "same problem\n",
    "['details', 'oriented,', 'efficient', 'and', 'organized,', 'able', 'to', 'meet', 'deadlines.']\n",
    "['strong', 'analytical', '&', 'technical', 'skills', '&', 'data', 'orientation.']\n",
    "['business', 'analyst']\n",
    "['director', 'of', 'data', 'science']\n",
    "['איש', 'ביג', 'דאטה', 'big', 'data', '|', 'מנהל', 'מוצר', '-', 'תוכנה']\n",
    "BI JOBS\n",
    "['taboola', 'protect', 'business', 'analyst']\n",
    "['business/data', 'analyst']\n",
    "['business', 'analyst']\n",
    "['business', 'operations', 'analyst-intern']\n",
    "['bi', 'analyst']\n",
    "\n",
    "analyst jobs\n",
    "['product', 'analyst']\n",
    "\n",
    "['junior', 'shipping', '&', 'payment', 'analyst']\n",
    "['customer', 'support', 'data', '&', 'operations', 'analyst']\n",
    "['operations', 'analyst']\n",
    "['fraud', 'analyst']\n",
    "['business', 'enablement', 'analyst']\n",
    "['junior', 'online', 'marketing', 'analyst']\n",
    "['strategy', 'analyst']\n",
    "['client', 'services', 'level', '2', 'analyst']\n",
    "['junior', 'game', 'analyst']\n",
    "['product', 'analyst']\n",
    "['product', 'data', 'scientist']\n",
    "['commission', 'analyst']\n",
    "['malware', 'analyst']\n",
    "['financial', 'analyst', '–', 'student', 'position']\n",
    "['product', 'analyst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write list of lists to csv file \n",
    "\n",
    "\n",
    "with open('urls.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(list_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "25\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "print(len(list_urls[0]))\n",
    "print(len(list_urls[1]))\n",
    "print(len(list_urls[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Click each link and parse text from the job posting page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Get the text portion including both title and job description of the job posting from a given url\n",
    "    \n",
    "    Parameters:\n",
    "        url: The job posting link\n",
    "        \n",
    "    Returns:\n",
    "        title: the job title (if \"data scientist\" is in the title)\n",
    "        posting: the job posting content    \n",
    "    \"\"\"\n",
    "\n",
    "def get_posting1(url):\n",
    "    soup = get_soup(url)\n",
    "    title = soup.find(name='h3').getText().lower()\n",
    "    posting = soup.find(name='div', attrs={'class': \"jobsearch-JobComponent\"}).get_text()\n",
    "    return title, posting.lower()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    get title + discribtion for every job posting url\n",
    "    \n",
    "    parameters: \n",
    "            url list 'urls'\n",
    "            \n",
    "    returns: \n",
    "            list with tuples job title and description\n",
    "'''\n",
    "\n",
    "posting_list =[]\n",
    "for i in range(0, len(list_urls[2])):\n",
    "    posting = get_posting1(list_urls[2][i])\n",
    "    posting_list.append(posting)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check len posting list \n",
    "data_eng = posting_list.copy()\n",
    "print(len(posting_list))\n",
    "print('posting_list')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data_sc))\n",
    "print(len(data_ana))\n",
    "print(len(data_eng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save posting list to csv\n",
    "# so will not have to run all process again\n",
    "\n",
    "\n",
    "df = pd.DataFrame(posting_list)\n",
    "df.head()\n",
    "df.to_csv('posting_list.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Get list of unique postings by keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    gets company name from description\n",
    "    \n",
    "    parameters: \n",
    "            listing\n",
    "            \n",
    "    returns: \n",
    "            company name\n",
    "'''\n",
    "\n",
    "\n",
    "def pick_company(position):\n",
    "    pos_com = re.compile('^[^-]+')\n",
    "    sentence_l = pos_com.findall(position[1])\n",
    "    company = sentence_l[0][len(position[0]):]\n",
    "    \n",
    "    return company\n",
    "pick_company(posting_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "   filters listing list for listings with specific keywords\n",
    "    \n",
    "    parameters: \n",
    "            keywords and listings list\n",
    "            \n",
    "    returns: \n",
    "            sublist of listings which contain keywords\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "def filter_listings(key_word, posting_list):\n",
    "    listx = []\n",
    "    for k in posting_list:\n",
    "        if key_word[0] in k[0] and key_word[1] in k[0]:\n",
    "            if k in listx:\n",
    "                continue\n",
    "            else:\n",
    "                listx.append(k)\n",
    "    return listx\n",
    "\n",
    "data_sci_des =filter_listings(('data','scientist'), data_sc)\n",
    "data_ana_des =filter_listings(('data','analyst'), data_ana)\n",
    "data_eng_des =filter_listings(('data','engineer'), data_eng)\n",
    "print(len(data_sci_des))\n",
    "print(len(data_ana_des))\n",
    "print(len(data_eng_des))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "   generate list of non-identical duplicates\n",
    "    \n",
    "    parameters: \n",
    "            list of postings\n",
    "            \n",
    "    returns: \n",
    "            list with duplicates only\n",
    "'''\n",
    "def list_duplicates(data_sci_des):\n",
    "    print(len(data_sci_des),\" lengthlist\")\n",
    "    duplicates = []\n",
    "    for posting in range (len(data_sci_des)):\n",
    "        looping = posting + 1\n",
    "        while looping < len(data_sci_des):\n",
    "           \n",
    "            if fuzz.token_sort_ratio(data_sci_des[posting], data_sci_des[looping]) >= 70:\n",
    "                if fuzz.token_sort_ratio(data_sci_des[posting], data_sci_des[looping]) == 100:\n",
    "                    duplicates.append(data_sci_des[posting])\n",
    "                else:\n",
    "                    if data_sci_des[posting][0] == data_sci_des[looping][0]:\n",
    "                       \n",
    "                        if fuzz.partial_ratio(pick_company(data_sci_des[posting]), pick_company(data_sci_des[looping]))>80:\n",
    "                            print(pick_company(data_sci_des[posting]), pick_company(data_sci_des[looping]))\n",
    "                            print(fuzz.partial_ratio(pick_company(data_sci_des[posting]), pick_company(data_sci_des[looping])))\n",
    "                            print(\"yeees\")\n",
    "                            duplicates.append(data_sci_des[posting])\n",
    "                        else:\n",
    "                            print(fuzz.partial_ratio(pick_company(data_sci_des[posting]), pick_company(data_sci_des[looping])))\n",
    "                            print(\"not ehough\")\n",
    "                            print(0)\n",
    "                         \n",
    "                        \n",
    "                    \n",
    "                break\n",
    "            else:\n",
    "                looping += 1\n",
    "       \n",
    "        \n",
    "    return duplicates\n",
    "        \n",
    "data_sci_des1 =  list_duplicates(data_sci_des)\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "   generate list of postings without non-identical duplicates\n",
    "    \n",
    "    parameters: \n",
    "            list of postings\n",
    "            \n",
    "    returns: \n",
    "            list of postings without non identical duplicates.\n",
    "'''\n",
    "print(len(data_sci_des1))\n",
    "\n",
    "def delete_duplicates(listing_by_keyword):\n",
    "  #  dups = list_duplicates(listing_by_keyword)\n",
    "    for i in data_sci_des1:\n",
    "        listing_by_keyword.remove(i)\n",
    "    return listing_by_keyword\n",
    "\n",
    "data_sc_nodups =delete_duplicates(data_sci_des)\n",
    "print(len(data_sc_nodups))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a - playing with nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ie_preprocess(document):\n",
    "    sentences = nltk.sent_tokenize(document)\n",
    "    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "    sentences = [nltk.pos_tag(sent) for sent in sentences]\n",
    "    return sentences\n",
    "import nltk\n",
    "sentence = ie_preprocess(zzz[1][1])\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "my_text = ''\n",
    "for zz in zzz:\n",
    "    my_text += zz[1]\n",
    "#print(my_text)\n",
    "\n",
    "tokens = word_tokenize(my_text)\n",
    "print(len(tokens))\n",
    "#print(tokens)\n",
    "print('number of unique words')\n",
    "print(len(set(tokens)))\n",
    "\n",
    "filtered_words = [word.lower() for word in tokens if word not in stopwords.words('english')]\n",
    "print('no stopwords')\n",
    "print(len(filtered_words))\n",
    "words_freq = {}\n",
    "\n",
    "for word in filtered_words:\n",
    "    if word in words_freq.keys():\n",
    "        words_freq[word] += 1\n",
    "        continue\n",
    "    else:\n",
    "        words_freq[word] =1\n",
    "print(words_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract minimum qualification level\n",
    "\n",
    "def m_toar(posting):\n",
    "    ma = re.compile('(?:msc|m.sc.|master’s|תואר שני|advanced degree|masters|תואר מתקדם)')\n",
    "    phd = re.compile('(?:phd|phd.)')\n",
    "    ba = re.compile('(?:ba/|b.sc.|bsc|bachelor’s|first degree|תואר אקדמי)')\n",
    "    if len(ba.findall(posting)) > 0:\n",
    "        print('ba')\n",
    "        min_toar = 1\n",
    "    elif len(ma.findall(posting)) > 0: \n",
    "        print('ma')\n",
    "        min_toar = 2\n",
    "    elif len(phd.findall(posting)) > 0: \n",
    "        print('phd')\n",
    "        min_toar = 3\n",
    "    else:\n",
    "        min_toar = 0\n",
    "        print(posting)\n",
    "    return min_toar\n",
    "\n",
    "\n",
    "index = 0\n",
    "for zz in zzz:\n",
    "    print(index)\n",
    "    sent_bag = break_sentences(zz[1])\n",
    "    academic = thematic_ana(education,sent_bag)\n",
    "    #print(academic)\n",
    "    print()\n",
    "    toar = m_toar(zz[1])\n",
    "    print(\"the toar is!!!!!!!!!!!!\", toar)\n",
    "    index += 1       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(zzz[12][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. analyze listing content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_scope =['in this job you will:','requirements']\n",
    "prog_in =['python','java','tensorflow', 'sql', 'spark', 'kafka', 'r', 'cassandra', 'elasticsearch', 'bigquery', 'google cloud', 'docker', 'scala', 'c++','matlab']\n",
    "education = ['m.sc.', 'phd.','bsc/msc','master’s', 'computer science', 'cs', 'ee', 'mathematics', 'engineering', 'physics','related','degree', 'bachelor’s','statistics']\n",
    "experience = ['years', 'experience']\n",
    "optional = ['nice to have:', '– an advantage']\n",
    "skills =['communication', 'accuracy','visualization', 'machine learning', 'deep learning']\n",
    "junior = ['student']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "   generate list of composite sentenses in posting\n",
    "    \n",
    "    parameters: \n",
    "            one posting description string\n",
    "            \n",
    "    returns: \n",
    "            list of sentences in posting\n",
    "'''\n",
    "\n",
    "# analyse sentenses in listing\n",
    "\n",
    "def break_sentences(listing):\n",
    "\n",
    "    length_listing = len(listing)\n",
    "    sentence_l = []\n",
    "    sentence = re.compile('[^\\n]+\\n')\n",
    "    end_sentence = re.compile('[\\n](.+)\\-.+ago')\n",
    "    # the last part of the listing does not have line break in the end therefore needs special regex\n",
    "    \n",
    "    sentence_l = sentence.findall(listing)\n",
    "    end_sentence_l = end_sentence.findall(listing)\n",
    "    if len(sentence_l)> 0:   \n",
    "        sentence_l.append(end_sentence_l[0])\n",
    "   \n",
    "   \n",
    "    len_sentences = 0\n",
    "    for i in sentence_l:\n",
    "        len_sentences += len(i)\n",
    "    print(\"listing\", length_listing, \"sentences\", len_sentences)\n",
    "    if len_sentences/length_listing < 0.9:\n",
    "        sentence_l = sent_tokenize(listing)\n",
    "        print(\"tokenize\")\n",
    "        for i in sentence_l:\n",
    "            len_sentences += len(i)\n",
    "        print(len_sentences)\n",
    "    return sentence_l\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "   filters the relevant sentence by theme\n",
    "    \n",
    "    parameters: \n",
    "            theme( eg. education qualification, experience, etc.) and posting\n",
    "            \n",
    "    returns: \n",
    "            list of relevant sentences\n",
    "'''\n",
    "# problem this kind of cleaning breaks relevant expresions such as \"computer science\"\n",
    "\n",
    "def thematic_ana(theme, listing):\n",
    "  \n",
    "    temp_words = []\n",
    "    selected = []\n",
    "    for i in listing:\n",
    "        i = i.replace('/',' ')\n",
    "        words = i.split()\n",
    "        table = str.maketrans('', '', sub('\\+', '',string.punctuation))\n",
    "        stripped = [w.translate(table) for w in words]\n",
    "        for ii in stripped:\n",
    "            if ii in theme:\n",
    "                selected.append(stripped)\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "    return selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "for zz in zzz:\n",
    "    print(index)\n",
    "    print(zz)\n",
    "    print('')\n",
    "    sent_bag = break_sentences(zz[1])\n",
    "    prog_lang = thematic_ana(prog_in,sent_bag)\n",
    "    print(prog_lang)\n",
    "    print()\n",
    "    academic = thematic_ana(education,sent_bag)\n",
    "    print(academic)\n",
    "    print()\n",
    "    exp = thematic_ana(experience,sent_bag)\n",
    "    print(exp)\n",
    "    print()\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(zzz[3])\n",
    "print()\n",
    "bagg = break_sentences(zzz[3][1])\n",
    "temp_words = []\n",
    "selected = []\n",
    "for i in bagg:\n",
    "    print(i)\n",
    "    temp_words = i.split()\n",
    "    for word in temp_words:\n",
    "        word2 = word.replace('/',' ')\n",
    "        if word2.strip(',') in prog_in:\n",
    "            print(word2)\n",
    "            selected.append(i)\n",
    "            break\n",
    "        else:\n",
    "            print(\"+++++++++++++++++\", word2)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take posting list and count relevant vs. irrelevant\n",
    "############## how important it is to count relevant vs irrele\n",
    "\n",
    "data_scientist_jobs = defaultdict(list)\n",
    "#data_analyst_jobs = defaultdict(list)\n",
    "data_sci_des = []\n",
    "data_eng_des = []\n",
    "data_ana_des = []\n",
    "datasci_related = [] \n",
    "non_data_sc = []\n",
    "\n",
    "\n",
    "for k in posting_list:\n",
    "    if 'data' in k[0] and (('scientist' in k[0]) or ('science' in k[0])):\n",
    "        data_sci_des.append(k) \n",
    "        if k[0] in data_scientist_jobs.keys():\n",
    "            data_scientist_jobs[k[0]] += 1\n",
    "        else:\n",
    "            data_scientist_jobs[k[0]] = 1\n",
    "    elif 'data' in k[0] and 'engineer' in k[0]:\n",
    "        data_eng_des.append(k) \n",
    "        if k[0] in data_scientist_jobs.keys():\n",
    "            data_scientist_jobs[k[0]] += 1\n",
    "        else:\n",
    "            data_scientist_jobs[k[0]] = 1\n",
    "    elif 'data' in k[0] and 'analyst' in k[0]:\n",
    "        data_ana_des.append(k) \n",
    "        if k[0] in data_scientist_jobs.keys():\n",
    "            data_scientist_jobs[k[0]] += 1\n",
    "        else:\n",
    "            data_scientist_jobs[k[0]] = 1\n",
    "    elif 'data scientist' in k[1]:\n",
    "        datasci_related.append(k) \n",
    "        \n",
    "    else:\n",
    "        if k in  non_data_sc:\n",
    "            continue\n",
    "        else:\n",
    "            non_data_sc.append(k) \n",
    "        print(k)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('data science posting', len(data_sci_des))\n",
    "print('data engineer posting', len(data_eng_des))\n",
    "print('data analyst posting', len(data_ana_des))\n",
    "print('datasci_related', len(datasci_related))\n",
    "print('non data science', len(non_data_sc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in range(len(non_data_sc)):\n",
    "    print(h)\n",
    "    print(non_data_sc[h])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentence_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping code:\n",
    "for city in city_set:\n",
    "    for start in range(0, max_results_per_city, 10):\n",
    "        page = requests.get(\"https://il.indeed.com/jobs?q=data+scientist&l=tel+aviv&start=\" + str(start))\n",
    "        time.sleep(1)  #ensuring at least 1 second between page grabs\n",
    "        soup = BeautifulSoup(page.text, \"lxml\", from_encoding=\"utf-8\")\n",
    "        for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}): \n",
    "            #specifying row num for index of job posting in dataframe\n",
    "            #num = (len(sample_df) + 1)\n",
    "            # think this shouldnt be +1\n",
    "            num = (len(sample_df))\n",
    "            #creating an empty list to hold the data for each posting\n",
    "            job_post = [] \n",
    "            #append city name\n",
    "            job_post.append(city) \n",
    "            #grabbing job title\n",
    "            for a in div.find_all(name=\"a\", attrs={\"data-tn-element\":\"jobTitle\"}):\n",
    "   \n",
    "                job_post.append(a[\"title\"]) \n",
    "            #grabbing company name\n",
    "            company = div.find_all(name=\"span\", attrs={\"class\":\"company\"})\n",
    "            if len(company) > 0:\n",
    "                for b in company:\n",
    "                    job_post.append(b.text.strip()) \n",
    "            else:\n",
    "                sec_try = div.find_all(name=\"span\", attrs={\"class\":\"result-link-source\"})\n",
    "                for span in sec_try:\n",
    "                    job_post.append(span.text) \n",
    "            print(\"this is row 1!!!!\")\n",
    "            print(job_post)\n",
    "            #grabbing location name\n",
    "          #  for div in soup.find_all(name=\"div\", attrs={\"class\":\"companyInfoWrapper\"}): \n",
    "        \n",
    "                \n",
    "            c = soup.findAll(\"span\", attrs={'class': \"location\"})\n",
    "            for span in c:\n",
    "                temp1 = 0\n",
    "                temp1 = span.text\n",
    "                job_post.append(span.text) \n",
    "                print()\n",
    "                if len(temp1) > 0:\n",
    "                    break\n",
    "           \n",
    "            #grabbing summary text\n",
    "            d = soup.findAll(\"span\", attrs={\"class\": \"summary\"})\n",
    "            for span in d:\n",
    "                temp2 = 0\n",
    "                temp2 = span.text\n",
    "                job_post.append(span.text.strip())\n",
    "                if len(temp2) > 0:\n",
    "                    break\n",
    "           \n",
    "            \n",
    "            print(\"this is row 2!!!!\")\n",
    "            print(job_post)\n",
    "            #appending list of job post info to dataframe at index num\n",
    "            sample_df.iloc[num,:] = job_post\n",
    "#saving sample_df as a local csv file — define your own local path to save contents \n",
    "#sample_df.to_csv(\"C:\\Users\\lili\\Documents\\icode\\scraping\\ver1.csv\", encoding=\"utf-8\")\n",
    "print(sample_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# source\n",
    "* [Web Scraping Job Postings from Indeed](https://medium.com/@msalmon00/web-scraping-job-postings-from-indeed-96bd588dcb4b)\n",
    "* [Scraping Job Posting Data from Indeed using Selenium and BeautifulSoup](https://towardsdatascience.com/scraping-job-posting-data-from-indeed-using-selenium-and-beautifulsoup-dfc86230baac)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
